{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTA LIBRERIAS\n",
    "#====================================================#\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from googletrans import Translator, constants\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINIENDO THRESHOLD \n",
    "#==================================================================================#\n",
    "\n",
    "class_names = ['TOXIC','SEVERE TOXIC','OBSCENE','THREAT','INSULT','IDENTITY HATE']\n",
    "thresholds = [0.4,0.15,0.15,0.01,0.1,0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CARGAR ARCHIVO TOKENIZER\n",
    "#======================================================================================#\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CARGANDO MEJOR MODELO\n",
    "#======================================================================================#\n",
    "\n",
    "model = load_model('checkpoints/cp-toxic_sen10.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPIAR TEXTO DE ENTRADA\n",
    "#========================================================================================#\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    \n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCION PREDICTORA\n",
    "#=========================================================================================#\n",
    "\n",
    "translator = Translator()\n",
    "def predict(input_text):\n",
    "    input_text = preprocess_text(input_text)\n",
    "    \n",
    "    input_text = translator.translate(preprocess_text(input_text)).text\n",
    "    \n",
    "    text_tokenizer = tokenizer.texts_to_sequences([input_text])\n",
    "    text_padd = pad_sequences(text_tokenizer, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    pred = model.predict(text_padd)\n",
    "    \n",
    "    class_preds = []\n",
    "    class_names_preds = []\n",
    "    for i,p in enumerate(pred[0]):\n",
    "        thr = thresholds[i]\n",
    "        if p > thr:\n",
    "            class_preds.append(1)\n",
    "            class_names_preds.append(class_names[i])\n",
    "        else:\n",
    "            class_preds.append(0)\n",
    "    return class_preds, class_names_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOSTRAR PREDICCIONES DADO UN COMENTARIO DE ENTRADA\n",
    "#==============================================================================#\n",
    "def printPrediction(input_text):\n",
    "    preds = predict(input_text)\n",
    "    print(\"\\ncomment: \", input_text)\n",
    "    print(\"class: \",preds[0])\n",
    "    if len(preds[1]) == 0:\n",
    "        print(\"names: \",\"ninguno\")\n",
    "        return\n",
    "    print(\"names: \", ', '.join(n for n in preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "comment:  I'm going to hit you if you do not cooperate with me\n",
      "class:  [1, 0, 0, 1, 0, 1]\n",
      "names:  TOXIC, THREAT, IDENTITY HATE\n",
      "\n",
      "comment:  maravilloso lugar\n",
      "class:  [0, 0, 0, 0, 0, 0]\n",
      "names:  ninguno\n",
      "\n",
      "comment:  me senti como en cas\n",
      "class:  [0, 0, 0, 0, 0, 0]\n",
      "names:  ninguno\n",
      "\n",
      "comment:  i also sock puppet of this account suprise sincerely the man that will track you down from the internet and kill you\n",
      "class:  [1, 0, 0, 1, 1, 1]\n",
      "names:  TOXIC, THREAT, INSULT, IDENTITY HATE\n",
      "\n",
      "comment:  hay personas que lo hacen mejor que tu lo haces horrible es una completa mierda deberias retirarte\n",
      "class:  [1, 0, 1, 0, 1, 1]\n",
      "names:  TOXIC, OBSCENE, INSULT, IDENTITY HATE\n"
     ]
    }
   ],
   "source": [
    "#COMENTARIOS DE ENTRADA PARA VALIDAR EL MODELO\n",
    "#==============================================================================================#\n",
    "\n",
    "texts = [\"I'm going to hit you if you do not cooperate with me\",\n",
    "         \"maravilloso lugar\",  \n",
    "         \"me senti como en cas\",\n",
    "         \"i also sock puppet of this account suprise sincerely the man that will track you down from the internet and kill you\",\n",
    "         \"hay personas que lo hacen mejor que tu lo haces horrible es una completa mierda deberias retirarte\"]\n",
    "\n",
    "for t in texts:\n",
    "    printPrediction(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSIONES\n",
    "\n",
    "como se observa el modelo funciona bastante bien y logra identificar los comentarios mal intencionados. los umbrales de decisión por cada clase parecen ser los correctos.\n",
    "\n",
    "como mejora se pueden aumentar los comentarios para las etiquetas 1, y asi aumentar la presición en identificar este tipo de comentarios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
